{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta, date\n",
    "import matplotlib.pyplot as pl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Get latest delegation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_delegation_file(\n",
    "    rir, path_to_files = '../../data/processed/delegation_files/%s/asns'):\n",
    "    path_to_rir_delegation_files = path_to_files % rir\n",
    "    delegation_file_a = np.array(glob.glob(path_to_rir_delegation_files + '/*'))\n",
    "    delegation_file_a = np.sort(delegation_file_a)\n",
    "    return delegation_file_a[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 datetime transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datime2epoch(dt):\n",
    "    \"\"\"\n",
    "    Thi is an example script.\n",
    "\n",
    "    It seems that it has to have THIS docstring with a summary line, a blank line\n",
    "    and sume more text like here. Wow.\n",
    "    \"\"\"\n",
    "    # cast dt into string in case it isn't \n",
    "    dt = str(dt)\n",
    "    if dt != 'summary':\n",
    "        if str(dt) != 'nan':\n",
    "            if '_' in dt:\n",
    "                YYYY, mm, dd = dt.split('_')\n",
    "            else:\n",
    "                YYYY = dt[0:4]\n",
    "                mm = dt[4:6]\n",
    "                dd = dt[6:8]\n",
    "            return (\n",
    "                date(\n",
    "                    int(YYYY),\n",
    "                    int(mm),\n",
    "                    int(dd)\n",
    "                ) - date(1970 ,1, 1)\n",
    "            ).total_seconds()\n",
    "        else:\n",
    "            return -1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Get all ASes on paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visible_ases(bgp_table_dump_df, ixp_asn):\n",
    "    \"\"\"\n",
    "    Thi is an example script.\n",
    "\n",
    "    It seems that it has to have THIS docstring with a summary line, a blank line\n",
    "    and sume more text like here. Wow.\n",
    "    \"\"\"\n",
    "    # create set of IXP members\n",
    "    members_set = set()\n",
    "    # Loop\n",
    "    for as_path_str in bgp_table_dump_df.drop_duplicates(\n",
    "        'as-path')['as-path'].values:\n",
    "        as_path_list = as_path_str.split(',')\n",
    "        # if AS-PATH contains more than one AS\n",
    "        # If not, the IXP member is directly annoucing \n",
    "        # its routes to the monitor\n",
    "        if len(as_path_list) > 1:\n",
    "            # Removes path through HE (AS6939 from the path)\n",
    "            if int(as_path_list[0]) != 6939 and int(as_path_list[1]) != 6939:\n",
    "            # Checks if the route server is the once announcing the path\n",
    "            # If so, remove IXP ASN from path\n",
    "            # If not, it is direct member\n",
    "                if int(as_path_list[0]) == ixp_asn:\n",
    "                    init_val = 1\n",
    "                else:\n",
    "                    init_val = 0\n",
    "                for i in range(1, len(as_path_list)):\n",
    "                        members_set.add(int(as_path_list[i]))\n",
    "        else:\n",
    "            members_set.add(int(as_path_str))\n",
    "    return members_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Compute customer cone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_customer_cone(df, ixp_asn):\n",
    "    \"\"\"\n",
    "    Thi is an example script.\n",
    "\n",
    "    It seems that it has to have THIS docstring with a summary line, a blank line\n",
    "    and sume more text like here. Wow.\n",
    "    \"\"\"\n",
    "    # create set of IXP members\n",
    "    output_list = []\n",
    "    members_set = get_visible_ases(df, ixp_asn)\n",
    "    for asn in members_set:\n",
    "        tmp_set=set()\n",
    "        # Look for paths that contains `asn` on them\n",
    "        if ixp_asn != None:\n",
    "            all_paths_a = df.loc[\n",
    "                (\n",
    "                    df['as-path'].str.startswith(\"%s,\"% ixp_asn)\n",
    "                ) &\n",
    "                (\n",
    "                    (df['as-path'].str.contains(\",%s,\"% asn)) | \n",
    "                    (df['as-path'].str.endswith(\",%s\"% asn))\n",
    "                )]['as-path'].values\n",
    "        else:\n",
    "            all_paths_a = df.loc[\n",
    "                (\n",
    "                    (df['as-path'].str.contains(\"%s,\"% asn)) | \n",
    "                    (df['as-path'].str.contains(\",%s,\"% asn)) | \n",
    "                    (df['as-path'].str.endswith(\",%s\"% asn))\n",
    "                )]['as-path'].values\n",
    "        # Interate over candidate paths\n",
    "        for path_str in all_paths_a:\n",
    "            # Turn path into an array\n",
    "            path_a = np.array(path_str.split(',')).astype(int)\n",
    "            # Find `asn` downstream ASes.\n",
    "            # Those are the ones trail on the path\n",
    "            asn_location = np.where(path_a == asn)[0]\n",
    "            # It may have a loop that not have been filtered before\n",
    "            if len(asn_location) == 1:\n",
    "                # Add downstream ASes to the customer cone set\n",
    "                for i in range(int(asn_location), int(len(path_a))):\n",
    "                    tmp_set.add(path_a[i])\n",
    "        # appends results to the list\n",
    "        output_list.append((asn, len(tmp_set)))\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Find out largest transit providers at IXPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixp_under_analysis_list = [\n",
    "#     # Frankfurt (DE-CIX)\n",
    "#     'fra',\n",
    "#     # Paris (Frace-IX)\n",
    "#     'cdg',\n",
    "#     # Bangkok (BNKIX)\n",
    "    'bkk',\n",
    "#     # Johanesburg (JINX)\n",
    "#     'jnb',\n",
    "    # IX.br Sao Paulo\n",
    "    'saopaulo',\n",
    "    # CABASE-BUE\n",
    "    'eze',\n",
    "    # PIT Chile\n",
    "    'scl'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixp_rir_dict = {\n",
    "    # Frankfurt (DE-CIX)\n",
    "    'fra': 'ripe',\n",
    "    # Paris (Frace-IX)\n",
    "    'cdg': 'ripe',\n",
    "    # Bangkok (BNKIX)\n",
    "    'bkk': 'apnic',\n",
    "    # Johanesburg (JINX)\n",
    "    'jnb': 'afrinic',\n",
    "    # IX.br Sao Paulo\n",
    "    'saopaulo': 'lacnic',\n",
    "    # CABASE-BUE\n",
    "    'eze': 'lacnic',\n",
    "    # PIT Chile\n",
    "    'scl': 'lacnic'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixp_cc_dict = {\n",
    "#     # Frankfurt (DE-CIX)\n",
    "#     'fra': 'DE',\n",
    "#     # Paris (Frace-IX)\n",
    "#     'cdg': 'FR',\n",
    "    # Bangkok (BNKIX)\n",
    "    'bkk': 'TH',\n",
    "    # Johanesburg (JINX)\n",
    "    'jnb': 'ZA',\n",
    "    # IX.br Sao Paulo\n",
    "    'saopaulo': 'BR',\n",
    "    # CABASE-BUE\n",
    "    'eze': 'AR',\n",
    "    # PIT Chile\n",
    "    'scl': 'CL'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixp_asn_dict = {\n",
    "    'eze': 11058,\n",
    "    'scl': 61522,\n",
    "    # We do not care about this now\n",
    "    'fra': None,\n",
    "    # We do not care about this now\n",
    "    'cdg': None,\n",
    "    # We do not care about this now\n",
    "    'bkk': None,\n",
    "    # We do not care about this now\n",
    "    'jnb': None,\n",
    "    # We do not care about this now\n",
    "    'saopaulo': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_ixp_bgp_dumps_dirs = '../../data/processed/ribs/v4'\n",
    "ixp_bgp_dumps_dirs_a = np.array(glob.glob(path_to_ixp_bgp_dumps_dirs + '/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output data frame\n",
    "customer_cone_size_df = pd.DataFrame(\n",
    "    [], \n",
    "    columns=['asn', 'customer_cones_size', 'iata_code', 'date']\n",
    ")\n",
    "# Iterates over the IXPs under analysis\n",
    "for ixp in ixp_under_analysis_list:\n",
    "    # get all BGP table dumps\n",
    "    ixp_bgp_table_dump_files_a = np.array(glob.glob(path_to_ixp_bgp_dumps_dirs + '/' + ixp + '/*'))\n",
    "    # sort BGP table dumps by ASCENDING DATE\n",
    "    ixp_bgp_table_dump_files_a = np.sort(ixp_bgp_table_dump_files_a)\n",
    "#     # Loop over each BGP table dump (month-to-month analysis)\n",
    "#     for bgp_table_dump_file in ixp_bgp_table_dump_files_a:\n",
    "    bgp_table_dump_file = ixp_bgp_table_dump_files_a[-1]\n",
    "    # get snapshot's date --> DATETIME\n",
    "    date_datetime = datime2epoch(bgp_table_dump_file.split('/')[-1])\n",
    "    # get snapshot's date --> STR WITHOUT _\n",
    "    date_no_spaces_str = bgp_table_dump_file.split('/')[-1].replace('_','')\n",
    "    # get snapshot's date --> STR \n",
    "    date_str = bgp_table_dump_file.split('/')[-1]\n",
    "    # open pre-processed bgp table dump\n",
    "    bgp_table_dump_df = pd.read_csv(\n",
    "        bgp_table_dump_file,\n",
    "        header='infer',\n",
    "        sep=','\n",
    "    )\n",
    "    # Remove NaN path if exists\n",
    "    bgp_table_dump_df = bgp_table_dump_df.loc[\n",
    "        bgp_table_dump_df['as-path'].notnull()\n",
    "    ]\n",
    "    # find customer cones ASes from BGP table dump\n",
    "    # We filter out paths that contains HE\n",
    "    customer_cone_size_list = get_customer_cone(\n",
    "        bgp_table_dump_df.loc[\n",
    "            (~bgp_table_dump_df['as-path'].str.contains(',6939,')) &\n",
    "            (~bgp_table_dump_df['as-path'].str.startswith('6939,'))\n",
    "        ],\n",
    "        ixp_asn_dict[ixp]\n",
    "    )\n",
    "    # create DF with members' set\n",
    "    tmp_df = pd.DataFrame(\n",
    "        customer_cone_size_list,\n",
    "        columns=['asn', 'customer_cones_size']\n",
    "    )\n",
    "    tmp_df['iata_code'] = np.repeat(ixp, tmp_df.shape[0])\n",
    "    tmp_df['date'] =  np.repeat(date_str, tmp_df.shape[0])\n",
    "    customer_cone_size_df = pd.DataFrame.append(customer_cone_size_df, tmp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        asn customer_cones_size iata_code        date\n",
      "181  137557                   7       bkk  2019_07_01\n",
      "87     9891                  10       bkk  2019_07_01\n",
      "156    7470                  12       bkk  2019_07_01\n",
      "105   45758                  20       bkk  2019_07_01\n",
      "124   45796                  27       bkk  2019_07_01\n",
      "215   38794                  38       bkk  2019_07_01\n",
      "4      4621                  47       bkk  2019_07_01\n",
      "220   45458                  50       bkk  2019_07_01\n",
      "70     4750                  82       bkk  2019_07_01\n",
      "114   45265                 144       bkk  2019_07_01\n",
      "        asn customer_cones_size iata_code        date\n",
      "94    18678                  38       eze  2019_07_01\n",
      "312   11014                  44       eze  2019_07_01\n",
      "119   16814                  55       eze  2019_07_01\n",
      "34   262195                  67       eze  2019_07_01\n",
      "587   11664                  81       eze  2019_07_01\n",
      "257   19037                  82       eze  2019_07_01\n",
      "325    7049                 100       eze  2019_07_01\n",
      "435   52361                 113       eze  2019_07_01\n",
      "644    3549                 219       eze  2019_07_01\n",
      "448   52376                 254       eze  2019_07_01\n",
      "         asn customer_cones_size iata_code        date\n",
      "5533   28368                 153  saopaulo  2019_07_10\n",
      "5243   23106                 161  saopaulo  2019_07_10\n",
      "3652  267613                 168  saopaulo  2019_07_10\n",
      "5260   25933                 201  saopaulo  2019_07_10\n",
      "5039   53062                 202  saopaulo  2019_07_10\n",
      "5506   28329                 207  saopaulo  2019_07_10\n",
      "5798   61832                 209  saopaulo  2019_07_10\n",
      "4364    7049                 218  saopaulo  2019_07_10\n",
      "283   262589                 381  saopaulo  2019_07_10\n",
      "4503   16735                 903  saopaulo  2019_07_10\n",
      "        asn customer_cones_size iata_code        date\n",
      "42    16629                  25       scl  2019_07_01\n",
      "47    18747                  37       scl  2019_07_01\n",
      "318    3549                  41       scl  2019_07_01\n",
      "14   262195                  47       scl  2019_07_01\n",
      "283   21838                  48       scl  2019_07_01\n",
      "392   14259                  52       scl  2019_07_01\n",
      "159   19228                  57       scl  2019_07_01\n",
      "199   52280                  70       scl  2019_07_01\n",
      "35    22661                  87       scl  2019_07_01\n",
      "164    7004                  88       scl  2019_07_01\n"
     ]
    }
   ],
   "source": [
    "customer_cone_size_df = customer_cone_size_df.sort_values(['iata_code', 'customer_cones_size'])\n",
    "for iata_code in customer_cone_size_df.drop_duplicates('iata_code')['iata_code'].values:\n",
    "    print(\n",
    "        customer_cone_size_df.loc[\n",
    "            customer_cone_size_df['iata_code'] == iata_code\n",
    "        ].tail(10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Looking into Level3's footprint in AR and CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LACNIC delegation file\n",
    "lacnic_latest_df = pd.read_csv(\n",
    "    get_latest_delegation_file('lacnic'),\n",
    "    names=[\n",
    "        'rir',\n",
    "        'cc',\n",
    "        'resource',\n",
    "        'asn',\n",
    "        'void',\n",
    "        'allocation_date',\n",
    "        'status',\n",
    "        'hash'\n",
    "    ],\n",
    "    sep='|'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values\n",
    "lacnic_latest_df = lacnic_latest_df.sort_values('allocation_date', ascending=True)\n",
    "# Remove rows that do not contains ASNs\n",
    "lacnic_latest_df = lacnic_latest_df.loc[\n",
    "    lacnic_latest_df['asn'] != '*'\n",
    "]\n",
    "# Adds epoch column\n",
    "lacnic_latest_df['epoch'] = lacnic_latest_df['allocation_date'].apply(datime2epoch)\n",
    "# cast ASN to int to then use with BGP table dump data frame\n",
    "lacnic_latest_df['asn'] = lacnic_latest_df['asn'].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rir</th>\n",
       "      <th>cc</th>\n",
       "      <th>resource</th>\n",
       "      <th>asn</th>\n",
       "      <th>void</th>\n",
       "      <th>allocation_date</th>\n",
       "      <th>status</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lacnic</td>\n",
       "      <td>*</td>\n",
       "      <td>asn</td>\n",
       "      <td>*</td>\n",
       "      <td>10171</td>\n",
       "      <td>summary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lacnic</td>\n",
       "      <td>MX</td>\n",
       "      <td>asn</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "      <td>19890331</td>\n",
       "      <td>allocated</td>\n",
       "      <td>31986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lacnic</td>\n",
       "      <td>AR</td>\n",
       "      <td>asn</td>\n",
       "      <td>676</td>\n",
       "      <td>1</td>\n",
       "      <td>19900523</td>\n",
       "      <td>allocated</td>\n",
       "      <td>65335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lacnic</td>\n",
       "      <td>BR</td>\n",
       "      <td>asn</td>\n",
       "      <td>1251</td>\n",
       "      <td>1</td>\n",
       "      <td>19991112</td>\n",
       "      <td>allocated</td>\n",
       "      <td>99087.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lacnic</td>\n",
       "      <td>MX</td>\n",
       "      <td>asn</td>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "      <td>19910524</td>\n",
       "      <td>allocated</td>\n",
       "      <td>66696.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rir  cc resource   asn   void allocation_date     status     hash\n",
       "0  lacnic   *      asn     *  10171         summary        NaN      NaN\n",
       "1  lacnic  MX      asn   278      1        19890331  allocated  31986.0\n",
       "2  lacnic  AR      asn   676      1        19900523  allocated  65335.0\n",
       "3  lacnic  BR      asn  1251      1        19991112  allocated  99087.0\n",
       "4  lacnic  MX      asn  1292      1        19910524  allocated  66696.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lacnic_latest_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level3's ASes in AR and CL\n",
    "level3_ases_dict = {\n",
    "    \"eze\": 3549,\n",
    "    \"scl\": 21838\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AS nationalies of Level3's cc in eze\n",
      "   cc  asn\n",
      "0  AR  205\n",
      "1  UY    4\n",
      "AS nationalies of Level3's cc in scl\n",
      "   cc  asn\n",
      "0  AR    5\n",
      "1  BR    1\n",
      "2  CL   37\n"
     ]
    }
   ],
   "source": [
    "# Iterates over the IXPs under analysis\n",
    "for ixp in ['eze', 'scl']:\n",
    "    # create a set for CC\n",
    "    cc_set = set()\n",
    "    # get all BGP table dumps\n",
    "    ixp_bgp_table_dump_files_a = np.array(glob.glob(path_to_ixp_bgp_dumps_dirs + '/' + ixp + '/*'))\n",
    "    # sort BGP table dumps by ASCENDING DATE\n",
    "    ixp_bgp_table_dump_files_a = np.sort(ixp_bgp_table_dump_files_a)\n",
    "    #\n",
    "    bgp_table_dump_file = ixp_bgp_table_dump_files_a[-1]\n",
    "    # get snapshot's date --> DATETIME\n",
    "    date_datetime = datime2epoch(bgp_table_dump_file.split('/')[-1])\n",
    "    # get snapshot's date --> STR WITHOUT _\n",
    "    date_no_spaces_str = bgp_table_dump_file.split('/')[-1].replace('_','')\n",
    "    # get snapshot's date --> STR \n",
    "    date_str = bgp_table_dump_file.split('/')[-1]\n",
    "    # open pre-processed bgp table dump\n",
    "    bgp_table_dump_df = pd.read_csv(\n",
    "        bgp_table_dump_file,\n",
    "        header='infer',\n",
    "        sep=','\n",
    "    )\n",
    "    # Remove NaN path if exists\n",
    "    bgp_table_dump_df = bgp_table_dump_df.loc[\n",
    "        bgp_table_dump_df['as-path'].notnull()\n",
    "    ]\n",
    "    # create DF with members' set\n",
    "    all_paths_a = bgp_table_dump_df.loc[\n",
    "        (\n",
    "            bgp_table_dump_df['as-path'].str.startswith(\"%s,\"% ixp_asn_dict[ixp])\n",
    "        ) &\n",
    "        (\n",
    "            (bgp_table_dump_df['as-path'].str.contains(\",%s,\"% level3_ases_dict[ixp])) | \n",
    "            (bgp_table_dump_df['as-path'].str.endswith(\",%s\"% level3_ases_dict[ixp]))\n",
    "    )]['as-path'].values\n",
    "    # Interate over all paths\n",
    "    for path_str in all_paths_a:\n",
    "        # Turn path into an array\n",
    "        path_a = np.array(path_str.split(',')).astype(int)\n",
    "        # Find `asn` downstream ASes.\n",
    "        # Those are the ones trail on the path\n",
    "        asn_location = np.where(path_a == level3_ases_dict[ixp])[0]\n",
    "        # It may have a loop that not have been filtered before\n",
    "        if len(asn_location) == 1:\n",
    "            # Add downstream ASes to the customer cone set\n",
    "            for i in range(int(asn_location), int(len(path_a))):\n",
    "                cc_set.add(path_a[i])\n",
    "    print(\"AS nationalies of Level3's cc in %s\" % ixp)\n",
    "    print(\n",
    "        lacnic_latest_df.loc[\n",
    "            lacnic_latest_df['asn'].isin(list(cc_set))\n",
    "        ].groupby('cc')['asn'].count().reset_index()\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latam-ixp-obs",
   "language": "python",
   "name": "latam-ixp-obs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
